# Readme
Hereâ€™s a clean and professional README.md for your Emotion-Based Courtroom Deception Detection project using the Real-Life Deception Detection (RLDD) 2016 dataset:

---

# ğŸ­ Emotion-Based Courtroom Deception Detection

An AI-powered multimodal system to detect deception in courtroom testimonies using emotion analysis from video, audio, and text. Built on the Real-Life Deception Detection (RLDD) 2016 dataset, this project focuses on violent crimes such as assault, homicide, and domestic abuse.

---

## ğŸ“‚ Dataset

- Dataset: Real-Life Deception Detection (2016)
- Source: Real courtroom trial clips
- Modalities:
  - ğŸ¥ Video clips of testimony
  - ğŸ”Š Audio from the same clips
  - ğŸ“œ Transcribed text
  - ğŸ·ï¸ Annotations (Truth/Lie labels)

You can find this dataset publicly available for research use.

---

## ğŸ§  Project Objective

Predict whether a person is telling the truth or lying by analyzing emotional cues across modalities. The key idea is:

> Extract and average emotion probabilities â†’ Analyze emotional signatures â†’ Predict deception (Truth vs Lie)

---

## ğŸ’¼ Crime Focus

We align this work with two highly emotion-relevant crime categories:
- ğŸ”ª Violent Crimes (e.g. murder, assault, domestic violence)
- âš ï¸ Sexual Offenses (e.g. sexual assault, child abuse)

These scenarios typically involve heightened fear, guilt, anger, and sadness â€” ideal for emotional analysis.

---

## ğŸ—ï¸ Project Structure

```bash
RLDD_EmotionDeception_Project/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ clips/               # Video/audio clips
â”‚   â”œâ”€â”€ transcripts/         # Courtroom testimony transcripts
â”‚   â””â”€â”€ annotations.csv      # Labels: Truth or Lie
â”œâ”€â”€ features/
â”‚   â”œâ”€â”€ text_emotions.csv    # Text-based emotion scores
â”‚   â”œâ”€â”€ audio_features.csv   # Audio-based speech features
â”‚   â””â”€â”€ video_emotions.csv   # Visual emotion scores
â”œâ”€â”€ models/
â”‚   â””â”€â”€ classifier.py        # Deception detection model
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ analysis.ipynb       # EDA and modeling experiments
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ preprocessing.py     # Feature extraction helpers
â””â”€â”€ main.py                  # Main pipeline script
```

---

## ğŸ› ï¸ Methodology

1. ğŸ¯ Preprocessing
   - Align clips, transcripts, and labels
   - Clean and tokenize text

2. ğŸ§ª Feature Extraction (Multimodal)
   - Text: GoEmotions BERT for emotional tone
   - Audio: Librosa/OpenSMILE for pitch, pauses, energy
   - Video: DeepFace or FER+ for facial emotion recognition

3. ğŸ” Feature Fusion
   - Combine average emotion probabilities per clip
   - Merge with label data (Truth/Lie)

4. ğŸ¤– Model Training
   - Classifier: Random Forest, XGBoost, or Logistic Regression
   - Evaluation: Accuracy, F1-score, Confusion Matrix

5. ğŸ“Š Visualization
   - Emotion heatmaps
   - Truth vs Lie emotional signature differences
   - Feature importance plots

---

## ğŸ” Future Scope

- Temporal emotion shift tracking (e.g. frame-by-frame change)
- Use LSTM or Transformers on sequences
- Real-time deception probability output

---

## ğŸ“š Dependencies

- Python 3.8+
- transformers, deepface, librosa, scikit-learn, pandas, numpy, matplotlib, seaborn, tqdm

Install all dependencies via:

```bash
pip install -r requirements.txt
```

---





